agg_myclusterDF <- sqldf(' select author,cluster,count(*) n from myclusterDF group by author,cluster' )
agg_myclusterDF <- agg_myclusterDF[order(agg_myclusterDF$author,decreasing = FALSE),]
agg_myclusterDF
#combine cluster info and analyze the spread
mycluster_k5 <- cbind(fedPapersDF,model_k5$cluster)
myclusterDF_k5 <- data.frame(mycluster_k5$author,mycluster_k5$`model_k5$cluster`)
colnames(myclusterDF_k5) <- c('author','cluster')
agg_myclusterDF_k5 <- sqldf(' select author,cluster,count(*) n from myclusterDF_k5 group by author,cluster' )
agg_myclusterDF_k5 <- agg_myclusterDF_k5[order(agg_myclusterDF_k5$author,decreasing = FALSE),]
agg_myclusterDF_k5
res.nbclust <- NbClust(MfedPapersDF, distance = "euclidean",
min.nc = 2, max.nc = 6,
method = "complete", index ="all")
factoextra::fviz_nbclust(res.nbclust) + theme_minimal() + ggtitle("NbClust's optimal number of clusters")
# get individual PCA
df.pca <- prcomp(df, center = TRUE, scale. = FALSE)
EnsurePackage("clustree")
tmp <- NULL
for (k in 1:6){
tmp[k] <- kmeans(MfedPapersDF, k, nstart = 30)
}
df <- data.frame(tmp)
# add a prefix to the column names
colnames(df) <- seq(1:6)
colnames(df) <- paste0("k",colnames(df))
# get individual PCA
df.pca <- prcomp(df, center = TRUE, scale. = FALSE)
ind.coord <- df.pca$x
ind.coord <- ind.coord[,1:2]
df <- bind_cols(as.data.frame(df), as.data.frame(ind.coord))
clustree(df, prefix = "k")
#HAC
d <- dist(as.matrix(MfedPapersDF))
hc <- hclust(d)
plot(hc)
hc <- hclust(d,method = 'ward.d2')
hc <- hclust(d)
plot(hc)
complete_Cluster <- hclust(dist(MfedPapersDF),method = 'complete')
complete_Cluster
average_Cluster <- hclust(dist(MfedPapersDF),method = 'average')
average_Cluster
plot(complete_Cluster)
plot(average_Cluster)
# import libraries
#create a function to ensure the libraries are imported
EnsurePackage <- function(x){
x <- as.character(x)
if (!require(x,character.only = TRUE)){
install.packages(pkgs=x, repos = "http://cran.us.r-project.org")
require(x, character.only = TRUE)
}
}
# usage example, to load the necessary library for further processing...
EnsurePackage("dplyr")
EnsurePackage("ggplot2")
EnsurePackage("sqldf")
EnsurePackage("reshape2")
EnsurePackage("wordcloud")
EnsurePackage("RColorBrewer")
EnsurePackage("tidyverse")
EnsurePackage("tidytext")
EnsurePackage("factoextra")
EnsurePackage("NbClust")
cat("All Packages are available")
#Load CSV into data frame
filepath <- "/Users/sathishrajendiran/Documents/R/fedPapers85.csv"
fedPapersDF <- data.frame(read.csv(filepath,na.strings=c(""," ","NA")),stringsAsFactors=FALSE)
dim(fedPapersDF) #85 72
# Analyze the spread
summary(fedPapersDF)
# compare number of articles by authors
table(fedPapersDF$author)
# view the data
View(fedPapersDF)
# Preview the structure
str(fedPapersDF)
#1. Keep only columns in scope
MfedPapersDF <- fedPapersDF[,3:ncol(fedPapersDF)]
#2. Check for missing values
#find incomplete records
nrow(MfedPapersDF[!complete.cases(MfedPapersDF),]) #0
#3. Find na columns
clnames <- colnames(MfedPapersDF)[colSums(is.na(MfedPapersDF)) > 0]
clnames #0
#1. Keep only columns in scope
MfedPapersDF <- fedPapersDF[,3:ncol(fedPapersDF)]
model_k3
clusplot(MfedPapersDF,model_k3$cluster,color=TRUE,shade=FALSE,labels=0,lines=0)
clusplot(MfedPapersDF,model_5k$cluster,color=TRUE,shade=FALSE,labels=0,lines=0)
model_k5
clusplot(MfedPapersDF,model_5k$cluster,color=TRUE,shade=FALSE,labels=0,lines=0)
fviz_nbclust(MfedPapersDF, mycluster_k5, method = "wss") +
geom_vline(xintercept = 4, linetype = 2)+
labs(subtitle = "Elbow method")
fviz_nbclust(MfedPapersDF, mycluster_k5, method = c("silhouette", "wss", "gap_stat"))
fviz_nbclust(MfedPapersDF, mycluster_k5, method = "wss") +
geom_vline(xintercept = 4, linetype = 2)+
labs(subtitle = "Elbow method")
# function to compute total within-cluster sum of squares
fviz_nbclust(MfedPapersDF, mycluster_k5, method = "wss", k.max = 24) + theme_minimal() + ggtitle("the Elbow Method")
# function to compute total within-cluster sum of squares
factoextra::fviz_nbclust(MfedPapersDF, mycluster_k5, method = "wss", k.max = 24) + theme_minimal() + ggtitle("the Elbow Method")
# function to compute total within-cluster sum of squares
factoextra::fviz_nbclust(MfedPapersDF, kmeans, method = "wss", k.max = 24) + theme_minimal() + ggtitle("the Elbow Method")
# Silhouette method
fviz_nbclust(MfedPapersDF, kmeans, method = "silhouette")+
labs(subtitle = "Silhouette method")
# Silhouette method
factoextra::fviz_nbclust(MfedPapersDF, kmeans, method = "silhouette")+
labs(subtitle = "Silhouette method")
factoextra::fviz_nbclust(MfedPapersDF, kmeans, nstart = 25,  method = "gap_stat", nboot = 50)+
labs(subtitle = "Gap statistic method")
set.seed(123)
# function to compute total within-cluster sum of squares
factoextra::fviz_nbclust(MfedPapersDF, kmeans, method = "wss", k.max = 24) + theme_minimal() + ggtitle("the Elbow Method")
set.seed(123)
# Silhouette method
factoextra::fviz_nbclust(MfedPapersDF, kmeans, method = "silhouette")+ labs(subtitle = "Silhouette method")
set.seed(123)
# Gap statistic
factoextra::fviz_nbclust(MfedPapersDF, kmeans, nstart = 25,  method = "gap_stat", nboot = 50)+ labs(subtitle = "Gap statistic method")
#Clustering using K-means with 2 clusters
set.seed(123)
model_k2 <- kmeans(na.omit(MfedPapersDF),2)
model_k2
clusplot(MfedPapersDF,model_k2$cluster,color=TRUE,shade=FALSE,labels=0,lines=0)
#combine cluster info and analyze the spread
mycluster_k2 <- cbind(fedPapersDF,model_k2$cluster)
myclusterDF_k2 <- data.frame(mycluster_k2$author,mycluster_k2$`model_k2$cluster`)
colnames(myclusterDF_k2) <- c('author','cluster')
agg_myclusterDF_k2 <- sqldf(' select author,cluster,count(*) n from myclusterDF_k2 group by author,cluster' )
agg_myclusterDF_k2 <- agg_myclusterDF_k2[order(agg_myclusterDF_k2$author,decreasing = FALSE),]
agg_myclusterDF_k2
# compare number of articles by authors
table(fedPapersDF$author)
# Analyze the spread
summary(fedPapersDF)
#Clustering using K-means with 4 clusters
set.seed(123)
model_k4 <- kmeans(na.omit(MfedPapersDF),4)
model_k4
# K-means clustering with 5 clusters of sizes 25, 17, 17, 21, 5
clusplot(MfedPapersDF,model_k4$cluster,color=TRUE,shade=FALSE,labels=0,lines=0)
model_k4
clusplot(MfedPapersDF,model_k3$cluster,color=TRUE,shade=FALSE,labels=0,lines=0,title='ss')
clusplot(MfedPapersDF,model_k3$cluster,color=TRUE,shade=FALSE,labels=0,lines=0,main='ss')
clusplot(MfedPapersDF,model_k3$cluster,color=TRUE,shade=FALSE,labels=0,lines=0,main='K-means with 4 clusters')
clusplot(MfedPapersDF,model_k3$cluster,color=TRUE,shade=FALSE,labels=0,lines=0,main='K-means with 3 clusters')
model_k3
clusplot(MfedPapersDF,model_k3$cluster,color=TRUE,shade=FALSE,labels=0,lines=0,main='K-means with 3 clusters')
#combine cluster info and analyze the spread
mycluster <- cbind(fedPapersDF,model_k3$cluster)
myclusterDF <- data.frame(mycluster$author,mycluster$`model_k$cluster`)
myclusterDF <- data.frame(mycluster$author,mycluster$`model_k3$cluster`)
colnames(myclusterDF) <- c('author','cluster')
agg_myclusterDF <- sqldf(' select author,cluster,count(*) n from myclusterDF group by author,cluster' )
agg_myclusterDF <- agg_myclusterDF[order(agg_myclusterDF$author,decreasing = FALSE),]
agg_myclusterDF
#Clustering using K-means with 4 clusters
set.seed(123)
model_k4 <- kmeans(na.omit(MfedPapersDF),4)
model_k4
clusplot(MfedPapersDF,model_k4$cluster,color=TRUE,shade=FALSE,labels=0,lines=0,main='K-means with 4 clusters')
#combine cluster info and analyze the spread
mycluster_k4 <- cbind(fedPapersDF,model_k4$cluster)
myclusterDF_k4 <- data.frame(mycluster_k4$author,mycluster_k4$`model_k4$cluster`)
colnames(myclusterDF_k4) <- c('author','cluster')
agg_myclusterDF_k4 <- sqldf(' select author,cluster,count(*) n from myclusterDF_k4 group by author,cluster' )
agg_myclusterDF_k4 <- agg_myclusterDF_k5[order(agg_myclusterDF_k5$author,decreasing = FALSE),]
agg_myclusterDF_k4
fviz_nbclust(MfedPapersDF, kmeans, method = c("silhouette", "wss", "gap_stat"))
set.seed(123)
# function to compute total within-cluster sum of squares
factoextra::fviz_nbclust(MfedPapersDF, kmeans, method = "wss", k.max = 24) + theme_minimal() + ggtitle("the Elbow Method")
set.seed(123)
# Silhouette method
factoextra::fviz_nbclust(MfedPapersDF, kmeans, method = "silhouette")+ labs(subtitle = "Silhouette method")
set.seed(123)
# Gap statistic
factoextra::fviz_nbclust(MfedPapersDF, kmeans, nstart = 25,  method = "gap_stat", nboot = 50)+ labs(subtitle = "Gap statistic method")
res.nbclust <- NbClust(MfedPapersDF, distance = "euclidean",
min.nc = 2, max.nc = 6,
method = "complete", index ="all")
factoextra::fviz_nbclust(res.nbclust) + theme_minimal() + ggtitle("NbClust's optimal number of clusters")
EnsurePackage("clustree")
tmp <- NULL
for (k in 1:6){
tmp[k] <- kmeans(MfedPapersDF, k, nstart = 30)
}
df <- data.frame(tmp)
# add a prefix to the column names
colnames(df) <- seq(1:6)
colnames(df) <- paste0("k",colnames(df))
# get individual PCA
df.pca <- prcomp(df, center = TRUE, scale. = FALSE)
ind.coord <- df.pca$x
ind.coord <- ind.coord[,1:2]
df <- bind_cols(as.data.frame(df), as.data.frame(ind.coord))
clustree(df, prefix = "k")
#HAC
d <- dist(as.matrix(MfedPapersDF))
hc <- hclust(d)
plot(hc)
complete_Cluster <- hclust(dist(MfedPapersDF),method = 'complete')
complete_Cluster
plot(complete_Cluster)
average_Cluster <- hclust(dist(MfedPapersDF),method = 'average')
average_Cluster
plot(average_Cluster)
#combine cluster info and analyze the spread
mycluster_k4 <- cbind(fedPapersDF,model_k4$cluster)
myclusterDF_k4 <- data.frame(mycluster_k4$author,mycluster_k4$`model_k4$cluster`)
colnames(myclusterDF_k4) <- c('author','cluster')
agg_myclusterDF_k4 <- sqldf(' select author,cluster,count(*) n from myclusterDF_k4 group by author,cluster' )
agg_myclusterDF_k4 <- agg_myclusterDF_k5[order(agg_myclusterDF_k5$author,decreasing = FALSE),]
agg_myclusterDF_k4 <- agg_myclusterDF_k4[order(agg_myclusterDF_k5$author,decreasing = FALSE),]
agg_myclusterDF_k4
#combine cluster info and analyze the spread
mycluster_k4 <- cbind(fedPapersDF,model_k4$cluster)
myclusterDF_k4 <- data.frame(mycluster_k4$author,mycluster_k4$`model_k4$cluster`)
colnames(myclusterDF_k4) <- c('author','cluster')
agg_myclusterDF_k4 <- sqldf(' select author,cluster,count(*) n from myclusterDF_k4 group by author,cluster' )
agg_myclusterDF_k4 <- agg_myclusterDF_k4[order(agg_myclusterDF_k4$author,decreasing = FALSE),]
agg_myclusterDF_k4
#Clustering using K-means with 3 clusters
set.seed(123)
model_k2 <- kmeans(na.omit(MfedPapersDF),2)
model_k2
clusplot(MfedPapersDF,model_k2$cluster,color=TRUE,shade=FALSE,labels=0,lines=0,main='K-means with 2 clusters')
#combine cluster info and analyze the spread
mycluster_k2 <- cbind(fedPapersDF,model_k2$cluster)
myclusterDF_k2 <- data.frame(mycluster_k2$author,mycluster_k2$`model_k2$cluster`)
colnames(myclusterDF_k2) <- c('author','cluster')
agg_myclusterDF_k2 <- sqldf(' select author,cluster,count(*) n from myclusterDF_k2 group by author,cluster' )
agg_myclusterDF_k2 <- agg_myclusterDF_k2[order(agg_myclusterDF_k2$author,decreasing = FALSE),]
agg_myclusterDF_k2
model_k2
#combine cluster info and analyze the spread
mycluster_k2 <- cbind(fedPapersDF,model_k2$cluster)
myclusterDF_k2 <- data.frame(mycluster_k2$author,mycluster_k2$`model_k2$cluster`)
colnames(myclusterDF_k2) <- c('author','cluster')
agg_myclusterDF_k2 <- sqldf(' select author,cluster,count(*) n from myclusterDF_k2 group by author,cluster' )
agg_myclusterDF_k2 <- agg_myclusterDF_k2[order(agg_myclusterDF_k2$author,decreasing = FALSE),]
agg_myclusterDF_k2
clusplot(MfedPapersDF,model_k2$cluster,color=TRUE,shade=FALSE,labels=0,lines=0,main='K-means with 2 clusters')
# Silhouette method
factoextra::fviz_nbclust(MfedPapersDF, kmeans, method = "silhouette")+ labs(subtitle = "Silhouette method")
# Gap statistic
factoextra::fviz_nbclust(MfedPapersDF, kmeans, nstart = 25,  method = "gap_stat", nboot = 50)+ labs(subtitle = "Gap statistic method")
res.nbclust <- NbClust(MfedPapersDF, distance = "euclidean",
min.nc = 2, max.nc = 6,
method = "complete", index ="all")
factoextra::fviz_nbclust(res.nbclust) + theme_minimal() + ggtitle("NbClust's optimal number of clusters")
complete_Cluster <- hclust(dist(MfedPapersDF),method = 'complete')
complete_Cluster
plot(complete_Cluster)
#create a function to ensure the libraries are imported
EnsurePackage <- function(x){
x <- as.character(x)
if (!require(x,character.only = TRUE)){
install.packages(pkgs=x, repos = "http://cran.us.r-project.org")
require(x, character.only = TRUE)
}
}
# usage example, to load the necessary library for further processing...
EnsurePackage("RWeka")
EnsurePackage("ggplot2"
#create a function to ensure the libraries are imported
EnsurePackage <- function(x){
x <- as.character(x)
if (!require(x,character.only = TRUE)){
install.packages(pkgs=x, repos = "http://cran.us.r-project.org")
require(x, character.only = TRUE)
}
}
# usage example, to load the necessary library for further processing...
EnsurePackage("RWeka")
EnsurePackage("ggplot2")
#create a function to ensure the libraries are imported
EnsurePackage <- function(x){
x <- as.character(x)
if (!require(x,character.only = TRUE)){
install.packages(pkgs=x, repos = "http://cran.us.r-project.org")
require(x, character.only = TRUE)
}
}
# usage example, to load the necessary library for further processing...
EnsurePackage("RWeka")
EnsurePackage("ggplot2")
cat("All Pacakges loaded")
#read from files
trainset <- read.csv("/Users/sathishrajendiran/Documents/R/Titanic/titanic-train.csv")
testset  <- read.csv("/Users/sathishrajendiran/Documents/R/Titanic/titanic-test.csv")
trainset
View(trainset)
View(testset)
#Preprocessing
NN <- make_Weka_filter("weka/filters/unsupervised/attribute/NumericToNominal")
trainset <- NN(data=trainset, control= Weka_control(R="1-3"), na.action = NULL)
testset <- NN(data=testset, control= Weka_control(R="1,3"), na.action = NULL)
#read from files
trainset <- read.csv("/Users/sathishrajendiran/Documents/R/Titanic/titanic-train.csv")
testset  <- read.csv("/Users/sathishrajendiran/Documents/R/Titanic/titanic-test.csv")
str(trainset)
str(testset)
#read from files
trainset <- read.csv("/Users/sathishrajendiran/Documents/R/Titanic/titanic-train.csv")
testset  <- read.csv("/Users/sathishrajendiran/Documents/R/Titanic/titanic-test.csv")
# View(trainset)
# View(testset)
str(trainset)
str(testset)
#read from files
trainset <- read.csv("/Users/sathishrajendiran/Documents/R/Titanic/titanic-train.csv")
testset  <- read.csv("/Users/sathishrajendiran/Documents/R/Titanic/titanic-test.csv")
# View(trainset)
# View(testset)
str(trainset)
cat("\n")
str(testset)
#Preprocessing
NN <- make_Weka_filter("weka/filters/unsupervised/attribute/NumericToNominal")
trainset <- NN(data=trainset, control= Weka_control(R="1-3"), na.action = NULL)
testset <- NN(data=testset, control= Weka_control(R="1,3"), na.action = NULL)
#Preprocessing
NN <- make_Weka_filter("weka/filters/unsupervised/attribute/NumericToNominal")
trainset <- NN(data=trainset, control= Weka_control(R="1-3"), na.action = NULL)
testset <- NN(data=testset, control= Weka_control(R="1,3"), na.action = NULL)
str(trainset)
cat("\n")
str(testset)
summary(trainset)
summary(testset)
#Preprocessing
NN <- make_Weka_filter("weka/filters/unsupervised/attribute/NumericToNominal")
trainset <- NN(data=trainset, control= Weka_control(R="1-3"), na.action = NULL)
testset <- NN(data=testset, control= Weka_control(R="1,3"), na.action = NULL)
str(trainset)
cat("\n")
str(testset)
cat("\n summary")
summary(trainset)
cat("\n")
summary(testset)
#Missing Values
MS <- make_Weka_filter("weka/filters/unsupervised/attribute/ReplaceMissingValues")
trainset <-MS(data=trainset, na.action = NULL)
testset <-MS(data=testset, na.action = NULL)
cat("\n summary")
summary(trainset)
cat("\n")
summary(testset)
#Missing Values
MS <- make_Weka_filter("weka/filters/unsupervised/attribute/ReplaceMissingValues")
trainset <-MS(data=trainset, na.action = NULL)
testset <-MS(data=testset, na.action = NULL)
cat("\n summary")
summary(trainset)
cat("\n")
summary(testset)
cat("\n Structure")
str(trainset)
cat("\n")
str(testset)
# model 1: no feature engineering
m=J48(Survived~., data = trainset)
m=J48(Survived~., data = trainset, control=Weka_control(U=FALSE, M=2,C=0.5))
WOW("J48")
e <- evaluate_Weka_classifier(m, numFolds = 10, seed = 1, class = TRUE)
summary(e)
e
#prediction
pred=predict (m, newdata = testset, type = c("class"))
pred
summary(pred)
pred
#prediction
pred=predict (m, newdata = testset, type = c("class"))
pred
summary(pred)
write.csv(pred, file="/Users/sathishrajendiran/Documents/R/Titanic/titanic-pred.csv")
#model 1: no feature engineering
m=J48(Survived~., data = trainset, control=Weka_control(U=FALSE, M=2, C=0.5))
e <- evaluate_Weka_classifier(m, numFolds = 10, seed = 1, class = TRUE)
pred=predict (m, newdata = testset, type = c("class"))
myids=c("PassengerId")
id_col=testset[myids]
newpred=cbind(id_col, pred)
colnames(newpred)=c("Passengerid", "Survived")
write.csv(newpred, file="/Users/sathishrajendiran/Documents/R/Titanic/titanic_pred1.csv", row.names=FALSE)
newpred
summary(newpred)
# model 2: some feature selection
myVars=c("Pclass", "Sex", "Age", "SibSp", "Parch", "Fare", "Survived")
newtrain=trainset[myVars]
newtest=testset[myVars]
m=J48(Survived~., data = newtrain)
m=J48(Survived~., data = newtrain, control=Weka_control(U=FALSE, M=2, C=0.5))
e=evaluate_Weka_classifier(m, seed=1, numFolds=10)
pred=predict (m, newdata = newtest, type = c("class"))
myids=c("PassengerId")
id_col=testset[myids]
newpred=cbind(id_col, pred)
colnames(newpred)=c("Passengerid", "Survived")
View(newpred)
write.csv(newpred, file="/Users/sathishrajendiran/Documents/R/Titanic/titanic_pred2.csv", row.names=FALSE)
summary(newpred)
# fviz_nbclust(MfedPapersDF, kmeans, method = c("silhouette", "wss", "gap_stat"))
set.seed(123)
# function to compute total within-cluster sum of squares
factoextra::fviz_nbclust(MfedPapersDF, kmeans, method = "wss", k.max = 24) + theme_minimal() + ggtitle("the Elbow Method")
set.seed(123)
# Silhouette method
factoextra::fviz_nbclust(MfedPapersDF, kmeans, method = "silhouette")+ labs(subtitle = "Silhouette method")
set.seed(123)
# Gap statistic
factoextra::fviz_nbclust(MfedPapersDF, kmeans, nstart = 25,  method = "gap_stat", nboot = 50)+ labs(subtitle = "Gap statistic method")
#create a function to ensure the libraries are imported
EnsurePackage <- function(x){
x <- as.character(x)
if (!require(x,character.only = TRUE)){
install.packages(pkgs=x, repos = "http://cran.us.r-project.org")
require(x, character.only = TRUE)
}
}
# usage example, to load the necessary library for further processing...
EnsurePackage("tensorflow")
EnsurePackage("ggplot2")
EnsurePackage("RWeka")
cat("All Pacakges loaded")
#create a function to ensure the libraries are imported
EnsurePackage <- function(x){
x <- as.character(x)
if (!require(x,character.only = TRUE)){
install.packages(pkgs=x, repos = "http://cran.us.r-project.org")
require(x, character.only = TRUE)
}
}
# usage example, to load the necessary library for further processing...
EnsurePackage("tensorflow")
EnsurePackage("ggplot2")
EnsurePackage("RWeka")
cat("All Pacakges loaded")
tf$constant("Hellow Tensorflow")
install_tensorflow()
#create a function to ensure the libraries are imported
EnsurePackage <- function(x){
x <- as.character(x)
if (!require(x,character.only = TRUE)){
install.packages(pkgs=x, repos = "http://cran.us.r-project.org")
require(x, character.only = TRUE)
}
}
# usage example, to load the necessary library for further processing...
EnsurePackage("tensorflow")
EnsurePackage("ggplot2")
EnsurePackage("RWeka")
cat("All Pacakges loaded")
#Install Tensorflow package
install_tensorflow()
#validate installation of tensorflow()
tf$constant("Hellow Tensorflow")
#validate installation of tensorflow()
tf$constant("Hellow Tensorflow")
#validate installation of tensorflow()
library(tensorflow)
tf$constant("Hellow Tensorflow")
tf.Tensor(b'Hellow Tensorflow', shape=(), dtype=string)
tf.Tensor('Hellow Tensorflow', shape=(), dtype=string)
tf$constant("Hellow Tensorflow")
tf$constant("Hellow Tensorflow")
#validate installation of tensorflow()
library(tensorflow)
tf$constant("Hellow Tensorflow")
hello <- tf$constant('Hello, World!')
sess <- tf$Session()
sess <- tf$Session()
sess = tf$Session()
hello <- tf$constant('Hello, TensorFlow!')
sess$run(hello)
sess = tf$Session()
help(tensorflow)
tf$constant("Hellow Tensorflow")
help(rpart)
#create a function to ensure the libraries are imported
EnsurePackage <- function(x){
x <- as.character(x)
if (!require(x,character.only = TRUE)){
install.packages(pkgs=x, repos = "http://cran.us.r-project.org")
require(x, character.only = TRUE)
}
}
# usage example, to load the necessary library for further processing...
EnsurePackage("tensorflow")
EnsurePackage("ggplot2")
EnsurePackage("RWeka")
cat("All Pacakges loaded")
#validate installation of tensorflow()
library(tensorflow)
tf$constant("Hellow Tensorflow")
# help(tensorflow)
#Install Tensorflow package
install_tensorflow()
#validate installation of tensorflow()
library(tensorflow)
tf$constant("Hellow Tensorflow")
#validate installation of tensorflow()
library(tensorflow)
tf$constant("Hellow Tensorflow")
tf$constant("Hellow Tensorflow")
tf$constant("Hellow Tensorflow")
